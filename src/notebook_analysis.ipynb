{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPros - An√°lisis de Clasificaci√≥n de Ingresos Adultos\n",
    "\n",
    "Este notebook proporciona un an√°lisis interactivo del modelo de clasificaci√≥n binaria para predecir si una persona gana m√°s de 50K al a√±o.\n",
    "\n",
    "## Objetivos:\n",
    "- Cargar y explorar los datos\n",
    "- Preprocesar las caracter√≠sticas\n",
    "- Entrenar un modelo de Regresi√≥n Log√≠stica\n",
    "- Evaluar el rendimiento del modelo\n",
    "- Visualizar resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count, isnan, isnull\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas exitosamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AdultIncomeAnalysis\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"‚úÖ Spark Session inicializada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir esquema para optimizar la carga\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", IntegerType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"hours_per_week\", IntegerType(), True),\n",
    "    StructField(\"label\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Cargar datos\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"../data/adult_income_sample.csv\")\n",
    "\n",
    "print(f\"üìä Datos cargados: {df.count()} registros\")\n",
    "print(f\"üìã Columnas: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar esquema y primeras filas\n",
    "print(\"üìã ESQUEMA DE DATOS:\")\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\nüìä PRIMERAS 10 FILAS:\")\n",
    "df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploraci√≥n de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"üìà ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "df.describe().show()\n",
    "\n",
    "# Verificar valores √∫nicos en variables categ√≥ricas\n",
    "print(\"\\nüîç VALORES √öNICOS EN VARIABLES CATEG√ìRICAS:\")\n",
    "print(\"Sexo:\", df.select(\"sex\").distinct().rdd.map(lambda row: row[0]).collect())\n",
    "print(\"Clase de trabajo:\", df.select(\"workclass\").distinct().rdd.map(lambda row: row[0]).collect())\n",
    "print(\"Educaci√≥n:\", df.select(\"education\").distinct().rdd.map(lambda row: row[0]).collect())\n",
    "print(\"Label:\", df.select(\"label\").distinct().rdd.map(lambda row: row[0]).collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Variables Categ√≥ricas\n",
    "\n",
    "### 3.1 StringIndexer - Transformaci√≥n de Variables Categ√≥ricas\n",
    "\n",
    "El StringIndexer convierte las variables categ√≥ricas de tipo string a √≠ndices num√©ricos. Esto es necesario antes de aplicar OneHotEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear StringIndexers para cada variable categ√≥rica\n",
    "sex_indexer = StringIndexer(inputCol=\"sex\", outputCol=\"sex_indexed\")\n",
    "workclass_indexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclass_indexed\")\n",
    "education_indexer = StringIndexer(inputCol=\"education\", outputCol=\"education_indexed\")\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_indexed\")\n",
    "\n",
    "print(\"‚úÖ StringIndexers creados para:\")\n",
    "print(\"   - sex ‚Üí sex_indexed\")\n",
    "print(\"   - workclass ‚Üí workclass_indexed\") \n",
    "print(\"   - education ‚Üí education_indexed\")\n",
    "print(\"   - label ‚Üí label_indexed\")\n",
    "\n",
    "# Aplicar StringIndexers para ver los √≠ndices asignados\n",
    "indexed_df = sex_indexer.fit(df).transform(df)\n",
    "indexed_df = workclass_indexer.fit(indexed_df).transform(indexed_df)\n",
    "indexed_df = education_indexer.fit(indexed_df).transform(indexed_df)\n",
    "indexed_df = label_indexer.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "print(\"\\nüìä √çNDICES ASIGNADOS POR STRINGINDEXER:\")\n",
    "print(\"Sexo:\")\n",
    "indexed_df.select(\"sex\", \"sex_indexed\").distinct().orderBy(\"sex_indexed\").show()\n",
    "\n",
    "print(\"Clase de trabajo:\")\n",
    "indexed_df.select(\"workclass\", \"workclass_indexed\").distinct().orderBy(\"workclass_indexed\").show()\n",
    "\n",
    "print(\"Educaci√≥n:\")\n",
    "indexed_df.select(\"education\", \"education_indexed\").distinct().orderBy(\"education_indexed\").show()\n",
    "\n",
    "print(\"Label:\")\n",
    "indexed_df.select(\"label\", \"label_indexed\").distinct().orderBy(\"label_indexed\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 OneHotEncoder - Codificaci√≥n One-Hot\n",
    "\n",
    "El OneHotEncoder convierte las variables categ√≥ricas indexadas en vectores binarios (one-hot encoding). Esto evita que el modelo interprete un orden en las categor√≠as que no existe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear OneHotEncoders para las variables categ√≥ricas indexadas\n",
    "sex_encoder = OneHotEncoder(inputCol=\"sex_indexed\", outputCol=\"sex_encoded\")\n",
    "workclass_encoder = OneHotEncoder(inputCol=\"workclass_indexed\", outputCol=\"workclass_encoded\")\n",
    "education_encoder = OneHotEncoder(inputCol=\"education_indexed\", outputCol=\"education_encoded\")\n",
    "\n",
    "print(\"‚úÖ OneHotEncoders creados para:\")\n",
    "print(\"   - sex_indexed ‚Üí sex_encoded\")\n",
    "print(\"   - workclass_indexed ‚Üí workclass_encoded\")\n",
    "print(\"   - education_indexed ‚Üí education_encoded\")\n",
    "\n",
    "# Aplicar OneHotEncoders\n",
    "encoded_df = sex_encoder.fit(indexed_df).transform(indexed_df)\n",
    "encoded_df = workclass_encoder.fit(encoded_df).transform(encoded_df)\n",
    "encoded_df = education_encoder.fit(encoded_df).transform(encoded_df)\n",
    "\n",
    "print(\"\\nüìä EJEMPLO DE CODIFICACI√ìN ONE-HOT:\")\n",
    "print(\"Primeras 5 filas con codificaci√≥n one-hot:\")\n",
    "encoded_df.select(\"sex\", \"sex_indexed\", \"sex_encoded\", \n",
    "                  \"workclass\", \"workclass_indexed\", \"workclass_encoded\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 VectorAssembler - Ensamblado de Caracter√≠sticas\n",
    "\n",
    "El VectorAssembler combina todas las caracter√≠sticas (num√©ricas y codificadas) en un solo vector de caracter√≠sticas que puede ser usado por el algoritmo de machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear VectorAssembler para combinar todas las caracter√≠sticas\n",
    "feature_columns = [\n",
    "    \"age\",                    # Variable num√©rica\n",
    "    \"fnlwgt\",                # Variable num√©rica  \n",
    "    \"hours_per_week\",        # Variable num√©rica\n",
    "    \"sex_encoded\",           # Variable categ√≥rica codificada\n",
    "    \"workclass_encoded\",     # Variable categ√≥rica codificada\n",
    "    \"education_encoded\"      # Variable categ√≥rica codificada\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_columns,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ VectorAssembler creado\")\n",
    "print(\"üìã Caracter√≠sticas incluidas:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "# Aplicar VectorAssembler\n",
    "final_df = assembler.transform(encoded_df)\n",
    "\n",
    "print(f\"\\nüìä Vector de caracter√≠sticas creado\")\n",
    "print(f\"üìè Dimensi√≥n del vector: {len(feature_columns)} caracter√≠sticas\")\n",
    "\n",
    "# Mostrar ejemplo del vector de caracter√≠sticas\n",
    "print(\"\\nüîç EJEMPLO DE VECTOR DE CARACTER√çSTICAS:\")\n",
    "final_df.select(\"features\").show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pipeline de Preprocesamiento\n",
    "\n",
    "Crear un pipeline que combine todos los pasos de preprocesamiento para facilitar la reutilizaci√≥n y el mantenimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear pipeline completo de preprocesamiento\n",
    "preprocessing_pipeline = Pipeline(stages=[\n",
    "    sex_indexer,\n",
    "    workclass_indexer,\n",
    "    education_indexer,\n",
    "    label_indexer,\n",
    "    sex_encoder,\n",
    "    workclass_encoder,\n",
    "    education_encoder,\n",
    "    assembler\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Pipeline de preprocesamiento creado\")\n",
    "print(\"üìã Etapas del pipeline:\")\n",
    "stages = [\n",
    "    \"1. StringIndexer (sex)\",\n",
    "    \"2. StringIndexer (workclass)\", \n",
    "    \"3. StringIndexer (education)\",\n",
    "    \"4. StringIndexer (label)\",\n",
    "    \"5. OneHotEncoder (sex)\",\n",
    "    \"6. OneHotEncoder (workclass)\",\n",
    "    \"7. OneHotEncoder (education)\",\n",
    "    \"8. VectorAssembler\"\n",
    "]\n",
    "\n",
    "for stage in stages:\n",
    "    print(f\"   {stage}\")\n",
    "\n",
    "# Aplicar pipeline completo\n",
    "print(\"\\nüîÑ Aplicando pipeline de preprocesamiento...\")\n",
    "processed_df = preprocessing_pipeline.fit(df).transform(df)\n",
    "\n",
    "print(\"‚úÖ Pipeline aplicado exitosamente\")\n",
    "print(f\"üìä Registros procesados: {processed_df.count()}\")\n",
    "print(f\"üìã Columnas finales: {len(processed_df.columns)}\")\n",
    "\n",
    "# Mostrar esquema final\n",
    "print(\"\\nüìã ESQUEMA FINAL:\")\n",
    "processed_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del Modelo de Regresi√≥n Log√≠stica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para entrenamiento\n",
    "train_data = processed_df.select(\"features\", \"label_indexed\")\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_df, test_df = train_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"üìä Divisi√≥n de datos:\")\n",
    "print(f\"   - Entrenamiento: {train_df.count()} registros (80%)\")\n",
    "print(f\"   - Prueba: {test_df.count()} registros (20%)\")\n",
    "\n",
    "# Crear modelo de Regresi√≥n Log√≠stica\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label_indexed\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01,\n",
    "    elasticNetParam=0.8\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Modelo de Regresi√≥n Log√≠stica configurado\")\n",
    "print(\"üìã Par√°metros del modelo:\")\n",
    "print(\"   - maxIter: 100\")\n",
    "print(\"   - regParam: 0.01 (regularizaci√≥n)\")\n",
    "print(\"   - elasticNetParam: 0.8 (mezcla L1/L2)\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nüîÑ Entrenando modelo...\")\n",
    "model = lr.fit(train_df)\n",
    "print(\"‚úÖ Modelo entrenado exitosamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en el conjunto de prueba\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Crear evaluadores\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "multi_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas\n",
    "auc = binary_evaluator.evaluate(predictions)\n",
    "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
    "precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"üìä M√âTRICAS DE RENDIMIENTO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"AUC         : {auc:.4f}\")\n",
    "print(f\"Accuracy    : {accuracy:.4f}\")\n",
    "print(f\"Precision   : {precision:.4f}\")\n",
    "print(f\"Recall      : {recall:.4f}\")\n",
    "print(f\"F1-Score    : {f1:.4f}\")\n",
    "\n",
    "# Mostrar matriz de confusi√≥n\n",
    "print(\"\\nüî¢ MATRIZ DE CONFUSI√ìN:\")\n",
    "confusion_matrix = predictions.groupBy(\"label_indexed\", \"prediction\").count().orderBy(\"label_indexed\", \"prediction\")\n",
    "confusion_matrix.show()\n",
    "\n",
    "# Mostrar ejemplos de predicciones\n",
    "print(\"\\nüîç EJEMPLOS DE PREDICCIONES:\")\n",
    "predictions.select(\"label_indexed\", \"prediction\", \"probability\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Importancia de Caracter√≠sticas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener coeficientes del modelo\n",
    "coefficients = model.coefficients.toArray()\n",
    "\n",
    "# Crear DataFrame con importancia de caracter√≠sticas\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Ordenar por valor absoluto del coeficiente\n",
    "feature_importance['abs_coefficient'] = abs(feature_importance['coefficient'])\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=True)\n",
    "\n",
    "print(\"üìä IMPORTANCIA DE CARACTER√çSTICAS:\")\n",
    "print(\"(Coeficientes de Regresi√≥n Log√≠stica)\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:20}: {row['coefficient']:8.4f}\")\n",
    "\n",
    "# Visualizar importancia de caracter√≠sticas\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['coefficient'])\n",
    "plt.title('Importancia de Caracter√≠sticas\\\\n(Coeficientes de Regresi√≥n Log√≠stica)')\n",
    "plt.xlabel('Coeficiente')\n",
    "plt.ylabel('Caracter√≠stica')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Completo y Guardado del Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear pipeline completo que incluye preprocesamiento y modelo\n",
    "full_pipeline = Pipeline(stages=[\n",
    "    sex_indexer,\n",
    "    workclass_indexer,\n",
    "    education_indexer,\n",
    "    label_indexer,\n",
    "    sex_encoder,\n",
    "    workclass_encoder,\n",
    "    education_encoder,\n",
    "    assembler,\n",
    "    lr\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Pipeline completo creado\")\n",
    "print(\"üìã Etapas del pipeline completo:\")\n",
    "full_stages = [\n",
    "    \"1. StringIndexer (sex)\",\n",
    "    \"2. StringIndexer (workclass)\", \n",
    "    \"3. StringIndexer (education)\",\n",
    "    \"4. StringIndexer (label)\",\n",
    "    \"5. OneHotEncoder (sex)\",\n",
    "    \"6. OneHotEncoder (workclass)\",\n",
    "    \"7. OneHotEncoder (education)\",\n",
    "    \"8. VectorAssembler\",\n",
    "    \"9. LogisticRegression\"\n",
    "]\n",
    "\n",
    "for stage in full_stages:\n",
    "    print(f\"   {stage}\")\n",
    "\n",
    "# Entrenar pipeline completo\n",
    "print(\"\\\\nüîÑ Entrenando pipeline completo...\")\n",
    "full_model = full_pipeline.fit(df)\n",
    "print(\"‚úÖ Pipeline completo entrenado\")\n",
    "\n",
    "# Guardar modelo\n",
    "import os\n",
    "output_path = \"../models/adult_income_model\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "full_model.write().overwrite().save(output_path)\n",
    "print(f\"üíæ Modelo guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen y Conclusiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìã RESUMEN DEL AN√ÅLISIS DE CLASIFICACI√ìN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìä DATOS PROCESADOS:\")\n",
    "print(f\"   ‚Ä¢ Total de registros: {df.count()}\")\n",
    "print(f\"   ‚Ä¢ Registros de entrenamiento: {train_df.count()}\")\n",
    "print(f\"   ‚Ä¢ Registros de prueba: {test_df.count()}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas utilizadas: {len(feature_columns)}\")\n",
    "\n",
    "print(f\"\\\\nüîß PREPROCESAMIENTO:\")\n",
    "print(f\"   ‚Ä¢ Variables categ√≥ricas indexadas: 4 (sex, workclass, education, label)\")\n",
    "print(f\"   ‚Ä¢ Variables categ√≥ricas codificadas: 3 (sex, workclass, education)\")\n",
    "print(f\"   ‚Ä¢ Variables num√©ricas: 3 (age, fnlwgt, hours_per_week)\")\n",
    "print(f\"   ‚Ä¢ Vector de caracter√≠sticas: {len(feature_columns)} dimensiones\")\n",
    "\n",
    "print(f\"\\\\nü§ñ MODELO:\")\n",
    "print(f\"   ‚Ä¢ Algoritmo: Regresi√≥n Log√≠stica\")\n",
    "print(f\"   ‚Ä¢ Regularizaci√≥n: ElasticNet (L1 + L2)\")\n",
    "print(f\"   ‚Ä¢ Par√°metro de regularizaci√≥n: 0.01\")\n",
    "print(f\"   ‚Ä¢ M√°ximo de iteraciones: 100\")\n",
    "\n",
    "print(f\"\\\\nüìà M√âTRICAS FINALES:\")\n",
    "print(f\"   ‚Ä¢ AUC: {auc:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {accuracy:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {recall:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\\\n‚úÖ RESULTADOS:\")\n",
    "if auc > 0.8:\n",
    "    print(\"   üéâ Excelente rendimiento del modelo (AUC > 0.8)\")\n",
    "elif auc > 0.7:\n",
    "    print(\"   üëç Buen rendimiento del modelo (AUC > 0.7)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Rendimiento del modelo puede mejorarse\")\n",
    "\n",
    "print(f\"\\\\nüöÄ PR√ìXIMOS PASOS:\")\n",
    "print(\"   ‚Ä¢ El modelo est√° listo para hacer predicciones sobre nuevos datos\")\n",
    "print(\"   ‚Ä¢ Se puede implementar en producci√≥n usando el pipeline guardado\")\n",
    "print(\"   ‚Ä¢ Considerar validaci√≥n cruzada para optimizaci√≥n de hiperpar√°metros\")\n",
    "print(\"   ‚Ä¢ Monitorear el rendimiento en datos de producci√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener Spark Session\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark Session detenida\")\n",
    "print(\"\\\\nüéâ ¬°An√°lisis completado exitosamente!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An√°lisis Detallado de Predicciones\n",
    "\n",
    "### 9.1 Predicciones con Probabilidades\n",
    "\n",
    "Vamos a analizar en detalle las predicciones del modelo, incluyendo las probabilidades asociadas y compararlas con las etiquetas reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame m√°s detallado con las predicciones\n",
    "detailed_predictions = predictions.select(\n",
    "    \"label_indexed\",\n",
    "    \"prediction\", \n",
    "    \"probability\",\n",
    "    \"rawPrediction\"\n",
    ")\n",
    "\n",
    "# Agregar informaci√≥n interpretable\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Funci√≥n para interpretar las etiquetas\n",
    "def interpret_label(label_idx):\n",
    "    return \">50K\" if label_idx == 1.0 else \"<=50K\"\n",
    "\n",
    "def interpret_prediction(pred_idx):\n",
    "    return \">50K\" if pred_idx == 1.0 else \"<=50K\"\n",
    "\n",
    "# Crear UDFs\n",
    "interpret_label_udf = udf(interpret_label, StringType())\n",
    "interpret_prediction_udf = udf(interpret_prediction, StringType())\n",
    "\n",
    "# Aplicar las funciones\n",
    "detailed_predictions = detailed_predictions.withColumn(\n",
    "    \"label_interpreted\", interpret_label_udf(\"label_indexed\")\n",
    ").withColumn(\n",
    "    \"prediction_interpreted\", interpret_prediction_udf(\"prediction\")\n",
    ")\n",
    "\n",
    "# Extraer probabilidades individuales\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def extract_prob_0(probability_vector):\n",
    "    return float(probability_vector[0])\n",
    "\n",
    "def extract_prob_1(probability_vector):\n",
    "    return float(probability_vector[1])\n",
    "\n",
    "extract_prob_0_udf = udf(extract_prob_0, DoubleType())\n",
    "extract_prob_1_udf = udf(extract_prob_1, DoubleType())\n",
    "\n",
    "detailed_predictions = detailed_predictions.withColumn(\n",
    "    \"prob_<=50K\", extract_prob_0_udf(\"probability\")\n",
    ").withColumn(\n",
    "    \"prob_>50K\", extract_prob_1_udf(\"probability\")\n",
    ")\n",
    "\n",
    "print(\"üìä PREDICCIONES DETALLADAS CON PROBABILIDADES:\")\n",
    "print(\"=\" * 80)\n",
    "detailed_predictions.select(\n",
    "    \"label_interpreted\",\n",
    "    \"prediction_interpreted\", \n",
    "    \"prob_<=50K\",\n",
    "    \"prob_>50K\",\n",
    "    \"probability\"\n",
    ").show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de casos correctos vs incorrectos\n",
    "correct_predictions = detailed_predictions.filter(\n",
    "    col(\"label_indexed\") == col(\"prediction\")\n",
    ")\n",
    "incorrect_predictions = detailed_predictions.filter(\n",
    "    col(\"label_indexed\") != col(\"prediction\")\n",
    ")\n",
    "\n",
    "print(f\"üìà AN√ÅLISIS DE PREDICCIONES:\")\n",
    "print(f\"   ‚Ä¢ Total de predicciones: {detailed_predictions.count()}\")\n",
    "print(f\"   ‚Ä¢ Predicciones correctas: {correct_predictions.count()}\")\n",
    "print(f\"   ‚Ä¢ Predicciones incorrectas: {incorrect_predictions.count()}\")\n",
    "print(f\"   ‚Ä¢ Tasa de acierto: {correct_predictions.count() / detailed_predictions.count() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\\\n‚úÖ EJEMPLOS DE PREDICCIONES CORRECTAS:\")\n",
    "correct_predictions.select(\n",
    "    \"label_interpreted\",\n",
    "    \"prediction_interpreted\", \n",
    "    \"prob_<=50K\",\n",
    "    \"prob_>50K\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "print(f\"\\\\n‚ùå EJEMPLOS DE PREDICCIONES INCORRECTAS:\")\n",
    "incorrect_predictions.select(\n",
    "    \"label_interpreted\",\n",
    "    \"prediction_interpreted\", \n",
    "    \"prob_<=50K\",\n",
    "    \"prob_>50K\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 An√°lisis de Confianza del Modelo\n",
    "\n",
    "Analicemos qu√© tan confiado est√° el modelo en sus predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de confianza del modelo\n",
    "from pyspark.sql.functions import when, max as spark_max, min as spark_min, avg\n",
    "\n",
    "# Calcular la confianza (probabilidad m√°xima)\n",
    "detailed_predictions = detailed_predictions.withColumn(\n",
    "    \"confidence\", \n",
    "    when(col(\"prediction\") == 1.0, col(\"prob_>50K\"))\n",
    "    .otherwise(col(\"prob_<=50K\"))\n",
    ")\n",
    "\n",
    "# Estad√≠sticas de confianza\n",
    "confidence_stats = detailed_predictions.select(\n",
    "    spark_min(\"confidence\").alias(\"min_confidence\"),\n",
    "    spark_max(\"confidence\").alias(\"max_confidence\"),\n",
    "    avg(\"confidence\").alias(\"avg_confidence\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"üéØ AN√ÅLISIS DE CONFIANZA DEL MODELO:\")\n",
    "print(f\"   ‚Ä¢ Confianza m√≠nima: {confidence_stats['min_confidence']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Confianza m√°xima: {confidence_stats['max_confidence']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Confianza promedio: {confidence_stats['avg_confidence']:.4f}\")\n",
    "\n",
    "# Distribuci√≥n de confianza\n",
    "print(f\"\\\\nüìä DISTRIBUCI√ìN DE CONFIANZA:\")\n",
    "detailed_predictions.select(\"confidence\").describe().show()\n",
    "\n",
    "# Casos de alta vs baja confianza\n",
    "high_confidence = detailed_predictions.filter(col(\"confidence\") >= 0.8)\n",
    "low_confidence = detailed_predictions.filter(col(\"confidence\") < 0.6)\n",
    "\n",
    "print(f\"\\\\nüîç CASOS DE ALTA CONFIANZA (‚â•0.8):\")\n",
    "print(f\"   ‚Ä¢ Cantidad: {high_confidence.count()}\")\n",
    "print(f\"   ‚Ä¢ Porcentaje: {high_confidence.count() / detailed_predictions.count() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\\\n‚ö†Ô∏è  CASOS DE BAJA CONFIANZA (<0.6):\")\n",
    "print(f\"   ‚Ä¢ Cantidad: {low_confidence.count()}\")\n",
    "print(f\"   ‚Ä¢ Porcentaje: {low_confidence.count() / detailed_predictions.count() * 100:.2f}%\")\n",
    "\n",
    "# Mostrar algunos casos de baja confianza\n",
    "print(f\"\\\\nüîç EJEMPLOS DE BAJA CONFIANZA:\")\n",
    "low_confidence.select(\n",
    "    \"label_interpreted\",\n",
    "    \"prediction_interpreted\", \n",
    "    \"confidence\",\n",
    "    \"prob_<=50K\",\n",
    "    \"prob_>50K\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Reflexi√≥n y An√°lisis de Resultados\n",
    "\n",
    "### ¬øQu√© observamos sobre los resultados?\n",
    "\n",
    "Bas√°ndonos en el an√°lisis realizado, podemos hacer las siguientes observaciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üéØ **Rendimiento del Modelo**\n",
    "\n",
    "1. **M√©tricas Generales**: El modelo muestra un rendimiento s√≥lido con m√©tricas como AUC, Accuracy, Precision, Recall y F1-Score que indican una buena capacidad de clasificaci√≥n.\n",
    "\n",
    "2. **Distribuci√≥n de Predicciones**: La mayor√≠a de las predicciones tienen una confianza razonable, lo que sugiere que el modelo est√° aprendiendo patrones significativos en los datos.\n",
    "\n",
    "3. **Casos de Alta Confianza**: Los casos donde el modelo tiene alta confianza (‚â•0.8) probablemente representan patrones claros y bien definidos en los datos.\n",
    "\n",
    "#### üîç **An√°lisis de Errores**\n",
    "\n",
    "1. **Casos de Baja Confianza**: Los casos con baja confianza (<0.6) pueden indicar:\n",
    "   - Patrones ambiguos en los datos\n",
    "   - Caracter√≠sticas que no est√°n bien capturadas por el modelo\n",
    "   - Casos l√≠mite donde las caracter√≠sticas no son determinantes\n",
    "\n",
    "2. **Predicciones Incorrectas**: Los errores del modelo pueden revelar:\n",
    "   - Limitaciones en las caracter√≠sticas utilizadas\n",
    "   - Necesidad de m√°s datos o caracter√≠sticas adicionales\n",
    "   - Casos donde el patr√≥n no es lineal\n",
    "\n",
    "#### üìä **Interpretaci√≥n de Caracter√≠sticas**\n",
    "\n",
    "1. **Variables Num√©ricas**: \n",
    "   - `age`: Probablemente tiene un impacto positivo en ingresos altos\n",
    "   - `hours_per_week`: Correlaci√≥n positiva con ingresos\n",
    "   - `fnlwgt`: Variable de ponderaci√≥n que puede no ser directamente interpretable\n",
    "\n",
    "2. **Variables Categ√≥ricas**:\n",
    "   - `education`: Factor clave en la predicci√≥n de ingresos\n",
    "   - `workclass`: Diferencia entre sectores p√∫blico y privado\n",
    "   - `sex`: Puede mostrar diferencias por g√©nero en los ingresos\n",
    "\n",
    "#### üöÄ **Implicaciones Pr√°cticas**\n",
    "\n",
    "1. **Uso en Producci√≥n**: El modelo puede ser utilizado para:\n",
    "   - Clasificaci√≥n autom√°tica de perfiles de ingresos\n",
    "   - An√°lisis de riesgo crediticio\n",
    "   - Estudios demogr√°ficos y socioecon√≥micos\n",
    "\n",
    "2. **Limitaciones**: \n",
    "   - El modelo se basa en correlaciones, no en causalidad\n",
    "   - Puede tener sesgos inherentes en los datos\n",
    "   - Requiere validaci√≥n continua con nuevos datos\n",
    "\n",
    "#### üîß **Mejoras Potenciales**\n",
    "\n",
    "1. **Ingenier√≠a de Caracter√≠sticas**:\n",
    "   - Crear nuevas caracter√≠sticas derivadas\n",
    "   - Considerar interacciones entre variables\n",
    "   - Normalizaci√≥n de variables num√©ricas\n",
    "\n",
    "2. **Optimizaci√≥n del Modelo**:\n",
    "   - Validaci√≥n cruzada para optimizaci√≥n de hiperpar√°metros\n",
    "   - Prueba de otros algoritmos (Random Forest, Gradient Boosting)\n",
    "   - Ensemble de m√∫ltiples modelos\n",
    "\n",
    "3. **Datos**:\n",
    "   - Recolecci√≥n de m√°s datos\n",
    "   - Balanceo de clases si es necesario\n",
    "   - Validaci√≥n de calidad de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis final de rendimiento por clase\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä AN√ÅLISIS FINAL POR CLASE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis de rendimiento por clase\n",
    "class_0_predictions = detailed_predictions.filter(col(\"label_indexed\") == 0.0)\n",
    "class_1_predictions = detailed_predictions.filter(col(\"label_indexed\") == 1.0)\n",
    "\n",
    "print(f\"\\\\nüìà CLASE <=50K (√çndice 0):\")\n",
    "print(f\"   ‚Ä¢ Total de casos: {class_0_predictions.count()}\")\n",
    "correct_class_0 = class_0_predictions.filter(col(\"prediction\") == 0.0).count()\n",
    "print(f\"   ‚Ä¢ Predicciones correctas: {correct_class_0}\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {correct_class_0 / class_0_predictions.count() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\\\nüìà CLASE >50K (√çndice 1):\")\n",
    "print(f\"   ‚Ä¢ Total de casos: {class_1_predictions.count()}\")\n",
    "correct_class_1 = class_1_predictions.filter(col(\"prediction\") == 1.0).count()\n",
    "print(f\"   ‚Ä¢ Predicciones correctas: {correct_class_1}\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {correct_class_1 / class_1_predictions.count() * 100:.2f}%\")\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\\\nüéØ RESUMEN FINAL:\")\n",
    "print(f\"   ‚Ä¢ Modelo entrenado con {df.count()} registros\")\n",
    "print(f\"   ‚Ä¢ Divisi√≥n: {train_df.count()} entrenamiento, {test_df.count()} prueba\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas utilizadas: {len(feature_columns)}\")\n",
    "print(f\"   ‚Ä¢ AUC: {auc:.4f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "\n",
    "if auc > 0.8:\n",
    "    print(f\"   üéâ ¬°Excelente rendimiento! El modelo est√° listo para producci√≥n.\")\n",
    "elif auc > 0.7:\n",
    "    print(f\"   üëç Buen rendimiento. Considerar optimizaciones adicionales.\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Rendimiento moderado. Se recomienda mejorar el modelo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predicci√≥n con Nuevos Datos\n",
    "\n",
    "### 11.1 Creaci√≥n de Datos de Prueba\n",
    "\n",
    "Vamos a crear un DataFrame con 9 registros nuevos para probar nuestro modelo entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datos de prueba con 9 registros nuevos\n",
    "new_data = [\n",
    "    # Registro 1: Profesional joven con educaci√≥n avanzada\n",
    "    (29, \"Male\", \"Private\", 180000, \"Masters\", 45, \">50K\"),\n",
    "    \n",
    "    # Registro 2: Empleado gubernamental con educaci√≥n media\n",
    "    (42, \"Female\", \"Gov\", 220000, \"Bachelors\", 40, \">50K\"),\n",
    "    \n",
    "    # Registro 3: Trabajador aut√≥nomo mayor\n",
    "    (58, \"Male\", \"Self-emp\", 350000, \"HS-grad\", 55, \">50K\"),\n",
    "    \n",
    "    # Registro 4: Joven con educaci√≥n b√°sica\n",
    "    (24, \"Female\", \"Private\", 95000, \"11th\", 25, \"<=50K\"),\n",
    "    \n",
    "    # Registro 5: Profesional experimentado\n",
    "    (47, \"Male\", \"Private\", 280000, \"Bachelors\", 50, \">50K\"),\n",
    "    \n",
    "    # Registro 6: Empleada gubernamental joven\n",
    "    (31, \"Female\", \"Gov\", 160000, \"Some-college\", 35, \"<=50K\"),\n",
    "    \n",
    "    # Registro 7: Trabajador aut√≥nomo con educaci√≥n avanzada\n",
    "    (52, \"Female\", \"Self-emp\", 320000, \"Masters\", 48, \">50K\"),\n",
    "    \n",
    "    # Registro 8: Empleado privado con educaci√≥n media\n",
    "    (38, \"Male\", \"Private\", 200000, \"Assoc\", 42, \"<=50K\"),\n",
    "    \n",
    "    # Registro 9: Profesional senior\n",
    "    (61, \"Male\", \"Gov\", 400000, \"Masters\", 40, \">50K\")\n",
    "]\n",
    "\n",
    "# Crear DataFrame con los nuevos datos\n",
    "new_df = spark.createDataFrame(new_data, schema)\n",
    "\n",
    "print(\"‚úÖ Datos de prueba creados\")\n",
    "print(f\"üìä Total de registros nuevos: {new_df.count()}\")\n",
    "\n",
    "# Mostrar los datos de entrada\n",
    "print(\"\\nüìã DATOS DE ENTRADA PARA PREDICCI√ìN:\")\n",
    "new_df.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Aplicaci√≥n del Modelo a Nuevos Datos\n",
    "\n",
    "Ahora vamos a aplicar nuestro modelo entrenado a estos nuevos datos para hacer predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el modelo entrenado a los nuevos datos\n",
    "print(\"üîÑ Aplicando modelo entrenado a nuevos datos...\")\n",
    "new_predictions = full_model.transform(new_df)\n",
    "\n",
    "print(\"‚úÖ Predicciones completadas\")\n",
    "\n",
    "# Crear funciones para interpretar los resultados\n",
    "def interpret_prediction_new(pred_idx):\n",
    "    return \">50K\" if pred_idx == 1.0 else \"<=50K\"\n",
    "\n",
    "def interpret_label_new(label_idx):\n",
    "    return \">50K\" if label_idx == 1.0 else \"<=50K\"\n",
    "\n",
    "def extract_prob_high_new(probability_vector):\n",
    "    return float(probability_vector[1])  # Probabilidad de >50K\n",
    "\n",
    "# Crear UDFs\n",
    "interpret_pred_udf_new = udf(interpret_prediction_new, StringType())\n",
    "interpret_label_udf_new = udf(interpret_label_new, StringType())\n",
    "extract_prob_udf_new = udf(extract_prob_high_new, DoubleType())\n",
    "\n",
    "# Agregar columnas interpretables\n",
    "new_results = new_predictions.withColumn(\n",
    "    \"prediction_interpreted\", interpret_pred_udf_new(\"prediction\")\n",
    ").withColumn(\n",
    "    \"label_interpreted\", interpret_label_udf_new(\"label_indexed\")\n",
    ").withColumn(\n",
    "    \"prob_>50K\", extract_prob_udf_new(\"probability\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Resultados procesados y listos para mostrar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Resultados de las Predicciones\n",
    "\n",
    "Vamos a mostrar los resultados de las predicciones con las probabilidades asociadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados detallados\n",
    "print(\"=\" * 100)\n",
    "print(\"üìä RESULTADOS DE PREDICCIONES EN NUEVOS DATOS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Mostrar tabla completa con predicciones\n",
    "new_results.select(\n",
    "    \"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\",\n",
    "    \"label_interpreted\", \"prediction_interpreted\", \"prob_>50K\"\n",
    ").show(truncate=False)\n",
    "\n",
    "# An√°lisis de precisi√≥n en nuevos datos\n",
    "correct_new = new_results.filter(col(\"label_indexed\") == col(\"prediction\")).count()\n",
    "total_new = new_results.count()\n",
    "accuracy_new = correct_new / total_new * 100\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISIS DE PRECISI√ìN EN NUEVOS DATOS:\")\n",
    "print(f\"   ‚Ä¢ Predicciones correctas: {correct_new}/{total_new}\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {accuracy_new:.2f}%\")\n",
    "\n",
    "# Mostrar casos incorrectos si los hay\n",
    "incorrect_new = new_results.filter(col(\"label_indexed\") != col(\"prediction\"))\n",
    "if incorrect_new.count() > 0:\n",
    "    print(f\"\\n‚ùå CASOS INCORRECTOS:\")\n",
    "    incorrect_new.select(\n",
    "        \"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\",\n",
    "        \"label_interpreted\", \"prediction_interpreted\", \"prob_>50K\"\n",
    "    ).show(truncate=False)\n",
    "else:\n",
    "    print(f\"\\n‚úÖ ¬°Todas las predicciones fueron correctas!\")\n",
    "\n",
    "# An√°lisis por nivel de confianza\n",
    "high_conf_new = new_results.filter(col(\"prob_>50K\") >= 0.8)\n",
    "medium_conf_new = new_results.filter((col(\"prob_>50K\") >= 0.6) & (col(\"prob_>50K\") < 0.8))\n",
    "low_conf_new = new_results.filter(col(\"prob_>50K\") < 0.6)\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISIS DE CONFIANZA:\")\n",
    "print(f\"   ‚Ä¢ Alta confianza (‚â•0.8): {high_conf_new.count()} casos\")\n",
    "print(f\"   ‚Ä¢ Confianza media (0.6-0.8): {medium_conf_new.count()} casos\")\n",
    "print(f\"   ‚Ä¢ Baja confianza (<0.6): {low_conf_new.count()} casos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 An√°lisis Detallado de Cada Caso\n",
    "\n",
    "Vamos a analizar cada caso individual para entender mejor las predicciones del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis detallado caso por caso\n",
    "print(\"üîç AN√ÅLISIS DETALLADO CASO POR CASO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convertir a Pandas para an√°lisis m√°s detallado\n",
    "new_results_pandas = new_results.toPandas()\n",
    "\n",
    "for i, row in new_results_pandas.iterrows():\n",
    "    print(f\"\\nüìã CASO {i+1}:\")\n",
    "    print(f\"   üë§ Perfil: {row['age']} a√±os, {row['sex']}, {row['workclass']}\")\n",
    "    print(f\"   üéì Educaci√≥n: {row['education']}, {row['hours_per_week']} hrs/semana\")\n",
    "    print(f\"   üéØ Real: {row['label_interpreted']}\")\n",
    "    print(f\"   ü§ñ Predicci√≥n: {row['prediction_interpreted']}\")\n",
    "    print(f\"   üìä Probabilidad >50K: {row['prob_>50K']:.3f}\")\n",
    "    \n",
    "    # An√°lisis del caso\n",
    "    if row['label_interpreted'] == row['prediction_interpreted']:\n",
    "        print(f\"   ‚úÖ CORRECTO\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå INCORRECTO\")\n",
    "    \n",
    "    # Interpretaci√≥n de la confianza\n",
    "    if row['prob_>50K'] >= 0.8:\n",
    "        conf_level = \"ALTA\"\n",
    "    elif row['prob_>50K'] >= 0.6:\n",
    "        conf_level = \"MEDIA\"\n",
    "    else:\n",
    "        conf_level = \"BAJA\"\n",
    "    \n",
    "    print(f\"   üéØ Confianza: {conf_level}\")\n",
    "\n",
    "print(f\"\\nüìä RESUMEN FINAL:\")\n",
    "print(f\"   ‚Ä¢ Total de casos analizados: {len(new_results_pandas)}\")\n",
    "print(f\"   ‚Ä¢ Predicciones correctas: {correct_new}\")\n",
    "print(f\"   ‚Ä¢ Predicciones incorrectas: {total_new - correct_new}\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n general: {accuracy_new:.2f}%\")\n",
    "\n",
    "# An√°lisis de patrones\n",
    "print(f\"\\nüîç PATRONES OBSERVADOS:\")\n",
    "high_income_cases = new_results_pandas[new_results_pandas['label_interpreted'] == '>50K']\n",
    "low_income_cases = new_results_pandas[new_results_pandas['label_interpreted'] == '<=50K']\n",
    "\n",
    "print(f\"   ‚Ä¢ Casos >50K: {len(high_income_cases)}\")\n",
    "print(f\"   ‚Ä¢ Casos <=50K: {len(low_income_cases)}\")\n",
    "\n",
    "if len(high_income_cases) > 0:\n",
    "    avg_prob_high = high_income_cases['prob_>50K'].mean()\n",
    "    print(f\"   ‚Ä¢ Probabilidad promedio para >50K: {avg_prob_high:.3f}\")\n",
    "\n",
    "if len(low_income_cases) > 0:\n",
    "    avg_prob_low = low_income_cases['prob_>50K'].mean()\n",
    "    print(f\"   ‚Ä¢ Probabilidad promedio para <=50K: {avg_prob_low:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluaci√≥n del Modelo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai-agent-professional-persona)",
   "language": "python",
   "name": "ai-agent-professional-persona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
