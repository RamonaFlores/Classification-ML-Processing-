# DataPros - ClasificaciÃ³n de Ingresos Adultos con Spark ML

## ðŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un modelo de **clasificaciÃ³n binaria** utilizando **Apache Spark ML** y **RegresiÃ³n LogÃ­stica** para predecir si una persona gana mÃ¡s de 50K al aÃ±o basÃ¡ndose en caracterÃ­sticas demogrÃ¡ficas y laborales.

### ðŸŽ¯ Objetivo
Construir un modelo de machine learning que permita a DataPros predecir la categorÃ­a de ingresos (>50K o <=50K) de una persona utilizando datos demogrÃ¡ficos y laborales.

## ðŸ“Š Datos

- **Archivo**: `adult_income_sample.csv`
- **Registros**: 2,000 registros simulados
- **CaracterÃ­sticas**:
  - `age`: Edad de la persona
  - `sex`: Sexo (Male/Female)
  - `workclass`: Clase de trabajo (Private, Gov, Self-emp)
  - `fnlwgt`: Peso final (variable de ponderaciÃ³n)
  - `education`: Nivel educativo
  - `hours_per_week`: Horas trabajadas por semana
  - `label`: Variable objetivo (>50K o <=50K)

## ðŸ—ï¸ Arquitectura del Proyecto

```
Classification-ML-Processing-/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ adult_income_sample.csv          # Datos de entrada
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adult_income_classification.py   # Script principal
â”‚   â”œâ”€â”€ notebook_analysis.ipynb          # AnÃ¡lisis interactivo
â”‚   â”œâ”€â”€ simple_demo.py                   # Demo simplificado
â”‚   â””â”€â”€ metrics_extractor.py             # Extractor de mÃ©tricas para dashboard
â”œâ”€â”€ dashboard_data/                      # MÃ©tricas y datos para dashboard
â”‚   â”œâ”€â”€ complete_metrics.json            # MÃ©tricas completas
â”‚   â”œâ”€â”€ kpi_metrics.json                 # KPIs principales
â”‚   â”œâ”€â”€ chart_data.json                  # Datos para grÃ¡ficos
â”‚   â”œâ”€â”€ findings.json                    # Findings y insights
â”‚   â”œâ”€â”€ executive_summary.json           # Resumen ejecutivo
â”‚   â””â”€â”€ README_DASHBOARD.md              # DocumentaciÃ³n del dashboard
â”œâ”€â”€ Dashboard/                           # Dashboard web (React/TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.tsx                      # Componente principal
â”‚   â”œâ”€â”€ package.json                     # Dependencias del dashboard
â”‚   â””â”€â”€ public/                          # Archivos estÃ¡ticos
â”œâ”€â”€ models/                              # Modelos entrenados (generado)
â”œâ”€â”€ requirements.txt                     # Dependencias Python
â””â”€â”€ README.MD                           # DocumentaciÃ³n
```

## ðŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Python 3.8+
- Java 8 o superior (requerido para Spark)
- Apache Spark 3.5.0

### InstalaciÃ³n

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd Classification-ML-Processing-
```

2. **Crear entorno virtual**:
```bash
python3 -m venv .venv
```

3. **Activar entorno virtual**:
```bash
# OpciÃ³n 1: Script automÃ¡tico
./activate_env.sh

# OpciÃ³n 2: Manual
source .venv/bin/activate
```

4. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

5. **Verificar instalaciÃ³n**:
```bash
python -c "import pyspark; print('PySpark:', pyspark.__version__)"
```

## ðŸ’» Uso

### OpciÃ³n 1: Script Principal
```bash
python src/adult_income_classification.py
```

### OpciÃ³n 2: Jupyter Notebook (Recomendado)
```bash
jupyter notebook src/notebook_analysis.ipynb
```

### OpciÃ³n 3: Demo Simplificado
```bash
python src/simple_demo.py
```

### OpciÃ³n 4: Generar MÃ©tricas para Dashboard
```bash
python src/metrics_extractor.py
```

## ðŸ”§ Proceso de Machine Learning

### 1. Carga de Datos
- Lectura del archivo CSV con esquema optimizado
- InspecciÃ³n del esquema y estadÃ­sticas descriptivas
- AnÃ¡lisis de valores nulos y distribuciones

### 2. Preprocesamiento de Variables CategÃ³ricas

#### StringIndexer
Convierte variables categÃ³ricas de tipo string a Ã­ndices numÃ©ricos:
```python
sex_indexer = StringIndexer(inputCol="sex", outputCol="sex_indexed")
workclass_indexer = StringIndexer(inputCol="workclass", outputCol="workclass_indexed")
education_indexer = StringIndexer(inputCol="education", outputCol="education_indexed")
label_indexer = StringIndexer(inputCol="label", outputCol="label_indexed")
```

#### OneHotEncoder
Convierte las variables categÃ³ricas indexadas en vectores binarios para evitar interpretaciones de orden:
```python
sex_encoder = OneHotEncoder(inputCol="sex_indexed", outputCol="sex_encoded")
workclass_encoder = OneHotEncoder(inputCol="workclass_indexed", outputCol="workclass_encoded")
education_encoder = OneHotEncoder(inputCol="education_indexed", outputCol="education_encoded")
```

### 3. Ensamblaje de CaracterÃ­sticas

#### VectorAssembler
Combina todas las caracterÃ­sticas en un vector Ãºnico:
```python
feature_columns = [
    "age",                    # Variable numÃ©rica
    "fnlwgt",                # Variable numÃ©rica  
    "hours_per_week",        # Variable numÃ©rica
    "sex_encoded",           # Variable categÃ³rica codificada
    "workclass_encoded",     # Variable categÃ³rica codificada
    "education_encoded"      # Variable categÃ³rica codificada
]

assembler = VectorAssembler(
    inputCols=feature_columns,
    outputCol="features"
)
```

### 4. DefiniciÃ³n y Entrenamiento del Modelo

#### Logistic Regression
```python
lr = LogisticRegression(
    featuresCol="features",
    labelCol="label_indexed",
    maxIter=100,
    regParam=0.01,
    elasticNetParam=0.8
)
```

#### Pipeline Completo
```python
full_pipeline = Pipeline(stages=[
    sex_indexer,
    workclass_indexer,
    education_indexer,
    label_indexer,
    sex_encoder,
    workclass_encoder,
    education_encoder,
    assembler,
    lr
])
```

## ðŸ“ˆ EvaluaciÃ³n del Modelo

### MÃ©tricas Utilizadas
- **AUC (Area Under Curve)**: Medida de la capacidad del modelo para distinguir entre clases
- **Accuracy**: ProporciÃ³n de predicciones correctas
- **Precision**: ProporciÃ³n de predicciones positivas que son correctas
- **Recall**: ProporciÃ³n de casos positivos que fueron identificados correctamente
- **F1-Score**: Media armÃ³nica entre precision y recall

### DivisiÃ³n de Datos
- **Entrenamiento**: 80% de los datos
- **Prueba**: 20% de los datos
- **Semilla aleatoria**: 42 (para reproducibilidad)

## ðŸŽ¨ Visualizaciones

El notebook incluye visualizaciones para:
- DistribuciÃ³n de la variable objetivo
- AnÃ¡lisis por sexo y educaciÃ³n
- Histogramas de variables numÃ©ricas
- Matriz de confusiÃ³n
- Importancia de caracterÃ­sticas (coeficientes)

## ðŸ“ Estructura del CÃ³digo

### Clase Principal: `AdultIncomeClassifier`

```python
class AdultIncomeClassifier:
    def __init__(self, app_name="AdultIncomeClassification")
    def load_data(self, file_path)
    def explore_data(self, df)
    def preprocess_data(self, df)
    def create_feature_pipeline(self)
    def train_model(self, df, pipeline)
    def evaluate_model(self, model, test_data)
    def save_model(self, model, output_path)
    def run_complete_pipeline(self, data_path, model_output_path)
```

### Pipeline de ML

1. **Carga de datos** con esquema optimizado
2. **ExploraciÃ³n** y anÃ¡lisis estadÃ­stico
3. **Preprocesamiento** de caracterÃ­sticas
4. **Entrenamiento** del modelo
5. **EvaluaciÃ³n** con mÃºltiples mÃ©tricas
6. **Persistencia** del modelo

## ðŸ” AnÃ¡lisis de CaracterÃ­sticas

### Variables NumÃ©ricas
- `age`: Edad (impacto positivo en ingresos altos)
- `fnlwgt`: Peso final (variable de ponderaciÃ³n)
- `hours_per_week`: Horas trabajadas (correlaciÃ³n positiva)

### Variables CategÃ³ricas
- `sex`: Sexo (diferencias por gÃ©nero)
- `workclass`: Clase de trabajo (sector pÃºblico vs privado)
- `education`: Nivel educativo (factor clave)

## ðŸš€ EjecuciÃ³n en ProducciÃ³n

### Cargar Modelo Entrenado
```python
from pyspark.ml import PipelineModel

# Cargar modelo
model = PipelineModel.load("models/adult_income_model")

# Hacer predicciones
predictions = model.transform(new_data)
```

### API REST (Opcional)
El modelo puede ser integrado en una API REST usando Flask/FastAPI para predicciones en tiempo real.

## ðŸ“Š Monitoreo y Mantenimiento

### MÃ©tricas de Monitoreo
- Drift de datos
- DegradaciÃ³n de rendimiento
- DistribuciÃ³n de predicciones

### Retrenamiento
- Frecuencia recomendada: Mensual
- Trigger: DegradaciÃ³n de mÃ©tricas > 5%

## ðŸ”§ ConfiguraciÃ³n de Spark

El proyecto utiliza las siguientes configuraciones optimizadas de Spark:

```python
spark = SparkSession.builder \
    .appName("AdultIncomeClassification") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()
```

## ðŸ“‹ Dependencias

```
pyspark==3.5.0
pandas==2.1.4
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
jupyter==1.0.0
scikit-learn==1.3.2
```

## ðŸ¤ Contribuciones

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## ðŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ðŸ‘¥ Equipo

- **DataPros Team** - Desarrollo y anÃ¡lisis
- **Machine Learning Engineers** - ImplementaciÃ³n del modelo

## ðŸ“ž Contacto

Para preguntas o soporte, contactar al equipo de DataPros.

---

**Nota**: Este proyecto es un ejemplo educativo de clasificaciÃ³n binaria con Spark ML. Para uso en producciÃ³n, se recomienda validaciÃ³n adicional y optimizaciÃ³n de hiperparÃ¡metros.

## ðŸŽ¯ Resultados Esperados

El modelo deberÃ­a alcanzar:
- **AUC**: > 0.80
- **Accuracy**: > 0.75
- **F1-Score**: > 0.70

## ðŸ“š Referencias

- [Apache Spark MLlib Documentation](https://spark.apache.org/docs/latest/ml-guide.html)
- [Logistic Regression in Spark](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression)
- [Feature Engineering with Spark](https://spark.apache.org/docs/latest/ml-features.html)
